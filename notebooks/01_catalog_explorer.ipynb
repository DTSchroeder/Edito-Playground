{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDITO Data Lake Playground\n",
    "This notebook walks through setup, catalog exploration, filtered searches, and asset visualization against the EDITO data API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Notebook setup and dependencies\n",
    "Install the required geospatial stack and configure a retry-friendly HTTP session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q requests pandas xarray matplotlib cartopy python-dotenv rasterio fsspec s3fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import requests\n",
    "import xarray as xr\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "def build_session() -> requests.Session:\n",
    "    \"\"\"Create a requests session with sensible retry defaults.\"\"\"\n",
    "    retry = Retry(total=5, backoff_factor=0.3, status_forcelist=[429, 500, 502, 503, 504], allowed_methods=(\"GET\", \"POST\"))\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    sess = requests.Session()\n",
    "    sess.headers.update({\"Accept\": \"application/json\"})\n",
    "    sess.mount(\"https://\", adapter)\n",
    "    sess.mount(\"http://\", adapter)\n",
    "    return sess\n",
    "\n",
    "session = build_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuring environment variables for API access\n",
    "Load credentials from the environment (or a `.env` file) and prepare shared paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "BASE_URL = os.getenv(\"EDITO_DATA_BASE_URL\", \"https://api.dive.edito.eu/data\").rstrip(\"/\")\n",
    "API_TOKEN = os.getenv(\"EDITO_API_TOKEN\")\n",
    "DOWNLOAD_DIR = Path(os.getenv(\"EDITO_DOWNLOAD_DIR\", \"../data\")).resolve()\n",
    "DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "session.headers.pop(\"Authorization\", None)\n",
    "if API_TOKEN:\n",
    "    session.headers[\"Authorization\"] = f\"Bearer {API_TOKEN}\"\n",
    "else:\n",
    "    print(\"Warning: EDITO_API_TOKEN is not set. Authenticated endpoints will fail.\")\n",
    "\n",
    "BASE_URL, DOWNLOAD_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring available collections via `/catalog`\n",
    "Use the STAC catalog root and the `/collections` endpoint to summarize available variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_url(path: str) -> str:\n",
    "    return path if path.startswith(\"http\") else f\"{BASE_URL}{path}\"\n",
    "\n",
    "def api_get(path: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    response = session.get(absolute_url(path), params=params, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def api_post(path: str, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    response = session.post(absolute_url(path), json=payload, timeout=90)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_root = api_get(\"/catalogs\")\n",
    "root_children = [\n",
    "    {\n",
    "        \"title\": link.get(\"title\"),\n",
    "        \"rel\": link.get(\"rel\"),\n",
    "        \"href\": link.get(\"href\")\n",
    "    }\n",
    "    for link in catalog_root.get(\"links\", [])\n",
    "    if link.get(\"rel\") == \"child\"\n",
    "]\n",
    "pd.DataFrame(root_children)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_payload = api_get(\"/collections\")\n",
    "collections = collections_payload.get(\"collections\", [])\n",
    "collections_df = pd.DataFrame([\n",
    "    {\n",
    "        \"id\": col.get(\"id\"),\n",
    "        \"title\": col.get(\"title\"),\n",
    "        \"license\": col.get(\"license\"),\n",
    "        \"time_start\": col.get(\"extent\", {}).get(\"temporal\", {}).get(\"interval\", [[None, None]])[0][0],\n",
    "        \"time_end\": col.get(\"extent\", {}).get(\"temporal\", {}).get(\"interval\", [[None, None]])[0][1],\n",
    "        \"bbox\": col.get(\"extent\", {}).get(\"spatial\", {}).get(\"bbox\", [[None]*4])[0],\n",
    "        \"keywords\": col.get(\"keywords\"),\n",
    "        \"links\": len(col.get(\"links\", [])),\n",
    "    }\n",
    "    for col in collections\n",
    "])\n",
    "collections_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query asset metadata with bounding boxes\n",
    "Build a helper around `/search` (STAC/OGC API) to filter by collection, bbox, and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stac_search(collection_id: str, bbox: List[float], datetime_range: str, limit: int = 10, max_pages: int = 3) -> List[Dict[str, Any]]:\n",
    "    body: Dict[str, Any] = {\n",
    "        \"collections\": [collection_id],\n",
    "        \"bbox\": bbox,\n",
    "        \"datetime\": datetime_range,\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    items: List[Dict[str, Any]] = []\n",
    "    url = \"/search\"\n",
    "    next_body = body\n",
    "    for _ in range(max_pages):\n",
    "        if next_body is not None:\n",
    "            payload = api_post(url, next_body)\n",
    "        else:\n",
    "            payload = api_get(url)\n",
    "        items.extend(payload.get(\"features\", []))\n",
    "        next_link = next((link.get(\"href\") for link in payload.get(\"links\", []) if link.get(\"rel\") == \"next\"), None)\n",
    "        if not next_link:\n",
    "            break\n",
    "        url = next_link\n",
    "        next_body = None\n",
    "    return items\n",
    "\n",
    "def summarize_items(features: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for feat in features:\n",
    "        assets = feat.get(\"assets\", {})\n",
    "        rows.append({\n",
    "            \"id\": feat.get(\"id\"),\n",
    "            \"collection\": feat.get(\"collection\"),\n",
    "            \"datetime\": feat.get(\"properties\", {}).get(\"datetime\"),\n",
    "            \"asset_count\": len(assets),\n",
    "            \"first_asset\": next(iter(assets.keys()), None),\n",
    "            \"bbox\": feat.get(\"bbox\"),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_ID = \"climate_forecast-sea_water_potential_temperature\"\n",
    "BBOX = [-10.0, 40.0, 10.0, 60.0]\n",
    "DATETIME = \"2024-10-01T00:00:00Z/2024-10-05T00:00:00Z\"\n",
    "search_results = stac_search(COLLECTION_ID, BBOX, DATETIME, limit=10, max_pages=2)\n",
    "summary_df = summarize_items(search_results)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download raster tiles into Xarray\n",
    "Select an asset, stream it to disk, and open it with `xarray` (delegating GeoTIFF support to Rasterio when needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not search_results:\n",
    "    raise RuntimeError(\"No search results to download. Adjust filters above.\")\n",
    "feature = search_results[0]\n",
    "asset_key = next((k for k, v in feature.get(\"assets\", {}).items() if \"data\" in v.get(\"roles\", [])), None)\n",
    "asset_key = asset_key or next(iter(feature[\"assets\"].keys()))\n",
    "asset = feature[\"assets\"][asset_key]\n",
    "asset_url = asset.get(\"href\")\n",
    "asset_key, asset_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_asset(url: str, chunk_size: int = 1024 * 1024) -> Path:\n",
    "    filename = url.split(\"/\")[-1] or \"asset.bin\"\n",
    "    destination = DOWNLOAD_DIR / filename\n",
    "    with session.get(url, stream=True, timeout=300) as response:\n",
    "        response.raise_for_status()\n",
    "        with open(destination, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    return destination\n",
    "\n",
    "local_asset = download_asset(asset_url)\n",
    "local_asset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_spatial_asset(path: Path) -> xr.DataArray | xr.Dataset:\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix in (\".tif\", \".tiff\"):\n",
    "        return xr.open_dataset(path, engine=\"rasterio\")\n",
    "    if suffix in (\".nc\", \".cdf\"):\n",
    "        return xr.open_dataset(path)\n",
    "    if suffix == \".zarr\":\n",
    "        return xr.open_zarr(path)\n",
    "    raise ValueError(f\"Unsupported asset format: {suffix}\")\n",
    "\n",
    "data_obj = open_spatial_asset(local_asset)\n",
    "data_obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize slices with Matplotlib and Cartopy\n",
    "Plot a quicklook using `cartopy` for geographic context and overlay the query bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(data_obj, xr.Dataset):\n",
    "    var_name = next(iter(data_obj.data_vars))\n",
    "    data_array = data_obj[var_name]\n",
    "else:\n",
    "    data_array = data_obj\n",
    "    var_name = data_array.name or \"variable\"\n",
    "\n",
    "slice_indexers = {dim: 0 for dim in data_array.dims if dim in (\"time\", \"depth\", \"lev\", \"band\")}\n",
    "plot_da = data_array.isel(**slice_indexers).squeeze()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "plot_da.plot(ax=ax, transform=ccrs.PlateCarree(), cmap=\"viridis\", cbar_kwargs={\"shrink\": 0.6, \"label\": var_name})\n",
    "ax.coastlines(resolution=\"110m\")\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.5)\n",
    "ax.set_title(f\"{var_name} quicklook\")\n",
    "min_lon, min_lat, max_lon, max_lat = BBOX\n",
    "ax.plot([min_lon, max_lon, max_lon, min_lon, min_lon], [min_lat, min_lat, max_lat, max_lat, min_lat], color=\"red\", linewidth=1, transform=ccrs.PlateCarree())\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}